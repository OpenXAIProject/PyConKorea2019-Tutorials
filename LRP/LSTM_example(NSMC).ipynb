{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "LSTM_example(NSMC).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvMYh3bfoTvZ",
        "colab_type": "text"
      },
      "source": [
        "런타임 유형변경 >> CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NqkqtpEUcvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 구글 드라이브와 Colab 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # 출력되는 URL에 접속하여 verification code 복사 및 붙여넣기"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiYat5GsUcrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 작업할 공간 설정\n",
        "import os\n",
        "os.getcwd() # 현재 path 확인"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRSCKBACoWuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/PyConKorea2019-Tutorials/LRP') # 작업할 path를 google drive로 이동\n",
        "os.getcwd()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZvq3H7koXsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install innvestigate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HyTcDPRS5T0",
        "colab_type": "text"
      },
      "source": [
        "### 1. 전처리 (base code :  https://cyc1am3n.github.io/2018/11/10/classifying_korean_movie_review.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq-rM5tTS5T2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import json\n",
        "# import os\n",
        "# import nltk\n",
        "# import pickle\n",
        "# import numpy as np\n",
        "# from pprint import pprint\n",
        "\n",
        "# if os.path.isfile('nsmc/train_docs_han.json'):\n",
        "#     with open('nsmc/train_docs_han.json') as f:\n",
        "#         train_docs = json.load(f)\n",
        "#     with open('nsmc/test_docs_han.json') as f:\n",
        "#         test_docs = json.load(f) \n",
        "\n",
        "# else:\n",
        "#     train_docs = [(tokenize(row[1]), row[2]) for row in train_data] #row[1]은 문장, row[2]는 클래스\n",
        "#     test_docs = [(tokenize(row[1]), row[2]) for row in test_data]\n",
        "\n",
        "#     with open('nsmc/train_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
        "#         json.dump(train_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
        "#     with open('nsmc/test_docs.json', 'w', encoding=\"utf-8\") as make_file:\n",
        "#         json.dump(test_docs, make_file, ensure_ascii=False, indent=\"\\t\")\n",
        "\n",
        "# pprint(train_docs[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaZs5xsnS5T6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokens = [t for d in train_docs for t in d[0]]\n",
        "# print(len(tokens))\n",
        "\n",
        "# text = nltk.Text(tokens, name='NMSC')\n",
        "# print(text)\n",
        "\n",
        "# train_y = [c for _, c in train_docs]\n",
        "# test_y = [c for _, c in test_docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzz2aVjF0DvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import pickle\n",
        "# import numpy as np\n",
        "# #load \n",
        "# with open(\"nsmc/train_y.txt\", \"wb\") as fp:\n",
        "#     pickle.dump(train_y, fp)\n",
        "# with open(\"nsmc/test_y.txt\", \"wb\") as fp:\n",
        "#     pickle.dump(test_y, fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "K1rXWgJkS5T9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 전체 토큰의 개수\n",
        "# print(len(text.tokens))\n",
        "\n",
        "# # 중복을 제외한 토큰의 개수\n",
        "# print(len(set(text.tokens)))            \n",
        "\n",
        "# # 출현 빈도가 높은 상위 토큰 10개\n",
        "# pprint(text.vocab().most_common(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M88rKLAFS5UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selected_words_10000 = [f[0] for f in text.vocab().most_common(10000)]\n",
        "\n",
        "# #train data\n",
        "# train_x_common_10000 = []\n",
        "# for i in range(len(train_docs)):\n",
        "#     _ = []\n",
        "#     for word in train_docs[i][0] :\n",
        "#         try : \n",
        "#             _.append(selected_words_10000.index(word))\n",
        "#         except :\n",
        "#             _.append(10000)\n",
        "#     train_x_common_10000.append(_)\n",
        "    \n",
        "# #test data\n",
        "# test_x_common_10000 = []\n",
        "# for i in range(len(test_docs)):\n",
        "#     _ = []\n",
        "#     for word in test_docs[i][0] :\n",
        "#         try : \n",
        "#             _.append(selected_words_10000.index(word))\n",
        "#         except :\n",
        "#             _.append(10000)\n",
        "#     test_x_common_10000.append(_)\n",
        "\n",
        "\n",
        "\n",
        "# # Save \n",
        "# x_train = np.asarray(train_x).astype('float32')\n",
        "# x_test = np.asarray(test_x).astype('float32')\n",
        "\n",
        "# y_train = np.asarray(train_y).astype('float32')\n",
        "# y_test = np.asarray(test_y).astype('float32')\n",
        "    \n",
        "# with open(\"selected_words_10000.txt\", \"wb\") as fp:\n",
        "#     pickle.dump(selected_words_10000, fp)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToSXWBuyS5UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "#load \n",
        "with open(\"nsmc/nsmc_train_x.txt\", \"rb\") as fp:\n",
        "    X_train = pickle.load(fp)\n",
        "with open(\"nsmc/nsmc_test_x.txt\", \"rb\") as fp:\n",
        "    X_test = pickle.load(fp)\n",
        "with open(\"nsmc/nsmc_train_y.txt\", \"rb\") as fp:\n",
        "    train_y = pickle.load(fp)\n",
        "with open(\"nsmc/nsmc_test_y.txt\", \"rb\") as fp:\n",
        "    test_y = pickle.load(fp)\n",
        "with open(\"nsmc/nsmc_selected_words.txt\", \"rb\") as fp:\n",
        "    selected_words_10000 = pickle.load(fp) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxFojuRES5UE",
        "colab_type": "text"
      },
      "source": [
        "### 2. LSTM 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OewKb16S5UF",
        "colab_type": "code",
        "outputId": "f595419a-4368-4a59-8bf6-0b050f888b7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "from numpy import newaxis as na"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm9TqutJS5UH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "maxlen = 100\n",
        "batch_size = 1024"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw1OdZpsS5UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One-hot encoding the output >> \n",
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(train_y, num_classes)\n",
        "y_test = keras.utils.to_categorical(test_y, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvfBz2MAS5UL",
        "colab_type": "code",
        "outputId": "8026b28b-0457-4561-d022-976450044693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('훈련 데이터: {}'.format(len(X_train)))\n",
        "print('테스트 데이터: {}'.format(len(X_test)))\n",
        "print('카테고리: {}'.format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터: 150000\n",
            "테스트 데이터: 50000\n",
            "카테고리: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Bc2GaSuS5UP",
        "colab_type": "code",
        "outputId": "801bed96-5c9c-4319-9d13-c3ed7385da0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.hist([len(s) for s in X_train], bins=50)\n",
        "plt.xlabel('length of Data')\n",
        "plt.ylabel('number of Data')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHDtJREFUeJzt3X2UHmWd5vHvNUGQEZAgbTYmsAka\nnUVXg7SA68uiKEZwDO46CONKQIboCiKjzkzQPQuinInjKzgubjTRMAdBVnDIwShmEHE8CqQDkYDo\nEiAMnQ2kJQgoHiR47R91NxSdfnnSqaefPOnrc06drvrV2110w4/7pe6SbSIiIprwJ50uQERE7DqS\nVCIiojFJKhER0ZgklYiIaEySSkRENCZJJSIiGpOkEhERjUlSiYiIxiSpREREY3Zr14UlHQBcDEwD\nDCyxfYGk/YBvAbOADcDxth+SJOAC4BjgMeBk2zeXay0A/ke59KdsLy/xQ4FvAHsCK4EPeYwpAvbf\nf3/PmjWruQeNiJgE1qxZ82vbPWMdp3ZN0yJpOjDd9s2S9gbWAMcBJwNbbC+WtAiYavvvJB0DfJAq\nqRwOXGD78JKE+oBequS0Bji0JKKbgDOBG6mSyoW2vzdauXp7e93X19eOR46I2GVJWmO7d6zj2tb8\nZXvTYE3D9qPAHcAMYD6wvBy2nCrRUOIXu3IDsG9JTG8BVtneYvshYBUwr+zbx/YNpXZyce1aERHR\nARPSpyJpFnAIVY1imu1NZdf9VM1jUCWc+2qn9ZfYaPH+YeIREdEhbU8qkvYCrgDOsv1IfV+pYbR9\nmmRJCyX1SeobGBho9+0iIiattiYVSc+iSiiX2L6yhB8oTVeD/S6bS3wjcEDt9JklNlp85jDxbdhe\nYrvXdm9Pz5j9TBERMU5tSyplNNdS4A7bn6/tWgEsKOsLgKtq8ZNUOQJ4uDSTXQMcLWmqpKnA0cA1\nZd8jko4o9zqpdq2IiOiAtg0pBl4DvAdYJ2ltiX0MWAxcLulU4F7g+LJvJdXIr/VUQ4pPAbC9RdIn\ngdXluPNsbynrH+DpIcXfK0tERHRI24YU76wypDgiYvt1fEhxRERMPkkqERHRmHb2qcQIZi367rDx\nDYuPneCSREQ0KzWViIhoTJJKREQ0JkklIiIak6QSERGNSVKJiIjGJKlERERjklQiIqIxSSoREdGY\nJJWIiGhMkkpERDQmSSUiIhqTpBIREY1JUomIiMYkqURERGOSVCIiojFtSyqSlknaLOm2WuxbktaW\nZcPgt+slzZL0+9q+r9TOOVTSOknrJV0oSSW+n6RVku4sP6e261kiIqI17aypfAOYVw/Yfpftubbn\nAlcAV9Z23zW4z/b7a/GLgNOAOWUZvOYi4Frbc4Bry3ZERHRQ25KK7R8DW4bbV2obxwOXjnYNSdOB\nfWzfYNvAxcBxZfd8YHlZX16LR0REh3SqT+V1wAO276zFZku6RdL1kl5XYjOA/tox/SUGMM32prJ+\nPzBtpJtJWiipT1LfwMBAQ48QERFDdSqpnMgzaymbgANtHwJ8GPimpH1avVipxXiU/Uts99ru7enp\nGW+ZIyJiDLtN9A0l7Qb8F+DQwZjtx4HHy/oaSXcBLwY2AjNrp88sMYAHJE23vak0k22eiPJHRMTI\nOlFTeRPwS9tPNWtJ6pE0pawfRNUhf3dp3npE0hGlH+Yk4Kpy2gpgQVlfUItHRESHtK2mIulS4Ehg\nf0n9wDm2lwInsG0H/euB8yQ9AfwReL/twU7+D1CNJNsT+F5ZABYDl0s6FbiXquO/q81a9N1h4xsW\nHzvBJYmIGJ+2JRXbJ44QP3mY2BVUQ4yHO74PeNkw8QeBo3aslBER0aS8UR8REY1JUomIiMYkqURE\nRGOSVCIiojFJKhER0ZgklYiIaEySSkRENCZJJSIiGpOkEhERjUlSiYiIxiSpREREY5JUIiKiMUkq\nERHRmCSViIhoTJJKREQ0ZsI/JzyZjPTRrYiIXVVqKhER0Zi2JRVJyyRtlnRbLXaupI2S1pblmNq+\nsyWtl/QrSW+pxeeV2HpJi2rx2ZJuLPFvSdq9Xc8SERGtaWdN5RvAvGHiX7A9tywrASQdTPXt+peW\nc/6XpCmSpgBfBt4KHAycWI4F+HS51ouAh4BT2/gsERHRgrYlFds/Bra0ePh84DLbj9u+B1gPHFaW\n9bbvtv0H4DJgviQBbwS+Xc5fDhzX6ANERMR260SfyhmSbi3NY1NLbAZwX+2Y/hIbKf484De2tw6J\nR0REB010UrkIeCEwF9gEfG4ibippoaQ+SX0DAwMTccuIiElpQocU235gcF3SV4Gry+ZG4IDaoTNL\njBHiDwL7Stqt1Fbqxw933yXAEoDe3l7v4GNMuNGGJm9YfOwEliQiYnQTWlORNL22+Q5gcGTYCuAE\nSXtImg3MAW4CVgNzykiv3ak681fYNnAd8M5y/gLgqol4hoiIGFnbaiqSLgWOBPaX1A+cAxwpaS5g\nYAPwPgDbt0u6HPgFsBU43faT5TpnANcAU4Bltm8vt/g74DJJnwJuAZa261kiIqI1bUsqtk8cJjzi\nf/htnw+cP0x8JbBymPjdVKPDIiJiJ5E36iMiojFJKhER0ZgklYiIaEySSkRENCZJJSIiGpOkEhER\njUlSiYiIxiSpREREY5JUIiKiMUkqERHRmDGnaZHUQzXP1sHAswfjtt/YxnJFREQXaqWmcglwBzAb\n+ATVRJCr21imiIjoUq0klefZXgo8Yft62++l+pRvRETEM7QyS/ET5ecmSccC/w/Yr31FioiIbtVK\nUvmUpOcCHwG+BOwDnNXWUkVERFdqJak8ZPth4GHgDQCSXtPWUkVERFdqpU/lSy3GIiJikhuxpiLp\n1cB/Anokfbi2ax+qT/vGTmDWou8OG9+w+NgJLklExOg1ld2BvagSz9615RHgnWNdWNIySZsl3VaL\nfUbSLyXdKuk7kvYt8VmSfi9pbVm+UjvnUEnrJK2XdKEklfh+klZJurP8nDqefwAREdGcEZNKGT78\nCeAI25+oLZ+3fWcL1/4GMG9IbBXwMtsvB/4vcHZt312255bl/bX4RcBpwJyyDF5zEXCt7TnAtWU7\nIiI6qJU+lcdKDWOlpB8OLmOdZPvHwJYhsR/Y3lo2bwBmjnYNSdOBfWzfYNvAxcBxZfd8YHlZX16L\nR0REh7T6Rv0vaf6N+vcC36ttz5Z0i6TrJb2uxGYA/bVj+ksMYJrtTWX9fmBaA2WKiIgd0JE36iV9\nHNhKlbAANgEH2j4E+DDwTUn7tHq9UovxKPdbKKlPUt/AwMAOlDwiIkbTSlJ5xhv1kg5hB96ol3Qy\n8Dbg3SUZYPtx2w+W9TXAXcCLgY08s4lsZokBPFCaxwabyTaPdE/bS2z32u7t6ekZb9EjImIMrSSV\n+hv1HwW+Bvz1eG4maR7wt8DbbT9Wi/dImlLWD6LqkL+7NG89IumIMurrJOCqctoKYEFZX1CLR0RE\nh4z5Rr3tq8vqU2/Ut0LSpcCRwP6S+oFzqEZ77QGsKiODbygjvV4PnCfpCeCPwPttD3byf4BqJNme\nVH0wg/0wi4HLJZ0K3Asc32rZIiKiPUZNKpLeAJwB/FkJ3QH8o+0fjXVh2ycOE146wrFXAFeMsK8P\neNkw8QeBo8YqR0RETJwRm7/KjMTLgKuBvwTeDawElkk6ZmKKFxER3WS0msrfAMfZ/nkttlZSH9Xc\nXyvbWrKIiOg6o3XU/7shCQUA27eSd0IiImIYoyWV341zX0RETFKjNX+9UNKKYeICDmpTeSIioouN\nllTmj7Lvs00XJCIiut+IScX29RNZkIiI6H6tvFEfERHRkiSViIhozGgvP/5T+fmhiStORER0s9E6\n6g+V9ALgvZIuphr19ZTa3FyxE8q36yOiE0ZLKl+h+kzvQcAanplUTIYVR0TEEKN9o/5C2/8BWGb7\nINuza0sSSkREbKOVqe//u6RXAIOf+P1xmaolIiLiGcYc/SXpTKrP/j6/LJdI+mC7CxYREd1nzJoK\n8FfA4bZ/ByDp08DPqGYqjoiIeEor76kIeLK2/SRDRoJFRERAazWVrwM3SvpO2T6OEb7gGBERk9uY\nNRXbnwdOAbaU5RTbX2zl4pKWSdos6bZabD9JqyTdWX5OLXFJulDSekm3Snpl7ZwF5fg7JS2oxQ+V\ntK6cc6HKh+8jIqIzWpqmxfbNZYjxhbZv2Y7rfwOYNyS2CLjW9hyq92AWlfhbgTllWQhcBFUSAs4B\nDgcOA84ZTETlmNNq5w29V0RETKC2zv1l+8dUtZu6+cDysr6cqjltMH6xKzcA+0qaDrwFWGV7i+2H\ngFXAvLJvH9s32DZwce1aERHRAZ2YUHKa7U1l/X6e/jTxDOC+2nH9JTZavH+YeEREdMioSUXSFEnX\ntevmpYbhdl1/kKSFkvok9Q0MDLT7dhERk9aoScX2k8AfJT23wXs+UJquKD83l/hG4IDacTNLbLT4\nzGHi27C9xHav7d6enp5GHiIiIrbVSvPXb4F1kpaWEVYXSrpwB+65AhgcwbUAuKoWP6mMAjsCeLg0\nk10DHC1paumgPxq4pux7RNIRZdTXSbVrRUREB7TynsqVZdluki4FjgT2l9RPNYprMXC5pFOBe4Hj\ny+ErgWOA9cBjVMOYsb1F0ieB1eW482rT7n+AaoTZnsD3yhIRER3SyoSSyyXtCRxo+1fbc3HbJ46w\n66hhjjVw+gjXWQYsGybeB7xse8oUERHt08qEkn8OrAW+X7bnSlrR7oJFRET3aaVP5Vyqlw5/A2B7\nLflAV0REDKOVpPKE7YeHxP7YjsJERER3a6Wj/nZJfwlMkTQHOBP4aXuL1V1G+h78zijfro+Idmql\npvJB4KXA48ClwCPAWe0sVEREdKdWRn89Bny8fJzLth9tf7EiIqIbtTL661WS1gG3Ur0E+XNJh7a/\naBER0W1a6VNZCnzA9r8CSHot1Ye7Xt7OgkVERPdppU/lycGEAmD7J8DW9hUpIiK61Yg1ldqXF6+X\n9L+pOukNvAv4UfuLFhER3Wa05q/PDdk+p7be9unqIyKi+4yYVGy/YSILEhER3W/MjnpJ+1JNKz+r\nfrztM9tXrIiI6EatjP5aCdwArCPTs0RExChaSSrPtv3htpckIiK6XitDiv9J0mmSpkvab3Bpe8ki\nIqLrtFJT+QPwGeDjPD3qy2T6+4iIGKKVpPIR4EW2f93uwkRERHdrpflr8JvxjZD0Eklra8sjks6S\ndK6kjbX4MbVzzpa0XtKvJL2lFp9XYuslLWqqjBERMT6t1FR+B6yVdB3V9PfA+IcUl+/czwWQNAXY\nCHwHOAX4gu3P1o+XdDBwAtX0+y8A/kXSi8vuLwNvBvqB1ZJW2P7FeMoVERE7rpWk8s9laYejgLts\n3ytppGPmA5fZfhy4R9J6qs8bA6y3fTeApMvKsUkqEREd0sr3VJa38f4nUM0pNugMSScBfcBHbD8E\nzKB6T2ZQf4kB3DckfvhwN5G0EFgIcOCBBzZT8oiI2EYr31O5R9LdQ5cdvbGk3YG3A/+nhC4CXkjV\nNLaJbeceGzfbS2z32u7t6elp6rIRETFEK81fvbX1ZwN/ATTxnspbgZttPwAw+BNA0leBq8vmRuCA\n2nkzS4xR4hER0QFj1lRsP1hbNtr+InBsA/c+kVrTl6TptX3vAG4r6yuAEyTtIWk2MAe4CVgNzJE0\nu9R6TijHRkREh7QyoeQra5t/QlVzaaWGM9o1n0M1aut9tfA/SJpL9WLlhsF9tm+XdDlVB/xW4HTb\nT5brnAFcA0wBltm+fUfKFRERO6aV5FDv29hK9R/843fkprZ/BzxvSOw9oxx/PnD+MPGVVBNeRkTE\nTqCV0V/5rkpERLSkleavPYD/yrbfUzmvfcWKiIhu1Erz11XAw8Aaam/UR0REDNVKUplpe17bSxIR\nEV2vlQklfyrpP7a9JBER0fVaqam8FjhZ0j1UzV8CbPvlbS1ZRER0nVaSylvbXoqIiNgltDKk+N6J\nKEhERHS/VvpUIiIiWpKkEhERjUlSiYiIxuzQxJCx65u16LvDxjcsbmKi6ojY1aSmEhERjUlSiYiI\nxiSpREREY5JUIiKiMUkqERHRmCSViIhoTMeSiqQNktZJWiupr8T2k7RK0p3l59QSl6QLJa2XdKuk\nV9aus6Acf6ekBZ16noiI6HxN5Q2259ruLduLgGttzwGuLdtQTWo5pywLgYugSkLAOcDhwGHAOYOJ\nKCIiJl6nk8pQ84HlZX05cFwtfrErNwD7SpoOvAVYZXuL7YeAVUA+KBYR0SGdTCoGfiBpjaSFJTbN\n9qayfj8wrazPAO6rndtfYiPFn0HSQkl9kvoGBgaafIaIiKjp5DQtr7W9UdLzgVWSflnfaduS3MSN\nbC8BlgD09vY2cs2IiNhWx2oqtjeWn5uB71D1iTxQmrUoPzeXwzcCB9ROn1liI8UjIqIDOpJUJD1H\n0t6D68DRwG3ACmBwBNcC4KqyvgI4qYwCOwJ4uDSTXQMcLWlq6aA/usQiIqIDOtX8NQ34jqTBMnzT\n9vclrQYul3QqcC9wfDl+JXAMsB54DDgFwPYWSZ8EVpfjzrO9ZeIeIyIi6jqSVGzfDbximPiDwFHD\nxA2cPsK1lgHLmi5jRERsv51tSHFERHSxJJWIiGhMkkpERDQmnxOOcclnhiNiOKmpREREY5JUIiKi\nMUkqERHRmCSViIhoTJJKREQ0JqO/Ahh5NFdExPZITSUiIhqTpBIREY1JUomIiMYkqURERGPSUb8d\n0pkdETG61FQiIqIxSSoREdGYCW/+knQAcDHVJ4UNLLF9gaRzgdOAgXLox2yvLOecDZwKPAmcafua\nEp8HXABMAb5me/FEPktsK7MXR0xunehT2Qp8xPbNkvYG1khaVfZ9wfZn6wdLOhg4AXgp8ALgXyS9\nuOz+MvBmoB9YLWmF7V9MyFNERMQ2Jjyp2N4EbCrrj0q6A5gxyinzgctsPw7cI2k9cFjZt7587x5J\nl5Vjk1QiIjqko30qkmYBhwA3ltAZkm6VtEzS1BKbAdxXO62/xEaKR0REh3QsqUjaC7gCOMv2I8BF\nwAuBuVQ1mc81eK+Fkvok9Q0MDIx9QkREjEtHkoqkZ1EllEtsXwlg+wHbT9r+I/BVnm7i2ggcUDt9\nZomNFN+G7SW2e2339vT0NPswERHxlAlPKpIELAXusP35Wnx67bB3ALeV9RXACZL2kDQbmAPcBKwG\n5kiaLWl3qs78FRPxDBERMbxOjP56DfAeYJ2ktSX2MeBESXOphhlvAN4HYPt2SZdTdcBvBU63/SSA\npDOAa6iGFC+zfftEPki0LkONIyaHToz++gmgYXatHOWc84Hzh4mvHO28iIiYWHmjPiIiGpMJJaOj\n0iwWsWtJTSUiIhqTpBIREY1J81fslNIsFtGdklSiq4z2obQknIjOS/NXREQ0JjWV2GWkySyi81JT\niYiIxqSmEru81GAiJk5qKhER0ZjUVCKGSM0mYvySVCJatLMlm9GGV48kiTHaLUklYgeN5z/uEbuq\nJJWI2OlqYdG90lEfERGNSU0lJq00W40tNZjYXkkqEZNIEmm0W9c3f0maJ+lXktZLWtTp8kRETGZd\nXVORNAX4MvBmoB9YLWmF7V90tmQRu7Y0i8VIujqpAIcB623fDSDpMmA+kKQS0QFJNtHtSWUGcF9t\nux84vENliYgRNNWXk+S08+v2pNISSQuBhWXzt5J+Nc5L7Q/8uplSdaU8f56/o8+vT3fy7p1//g77\n960c1O1JZSNwQG17Zok9g+0lwJIdvZmkPtu9O3qdbpXnz/Pn+Sfv87eq20d/rQbmSJotaXfgBGBF\nh8sUETFpdXVNxfZWSWcA1wBTgGW2b+9wsSIiJq2uTioAtlcCKyfodjvchNbl8vyTW54/xiTbnS5D\nRETsIrq9TyUiInYiSSotmmzTwUg6QNJ1kn4h6XZJHyrx/SStknRn+Tm102VtF0lTJN0i6eqyPVvS\njeVv4FtlcMguS9K+kr4t6ZeS7pD06kn2+//r8rd/m6RLJT17sv0NjEeSSgtq08G8FTgYOFHSwZ0t\nVdttBT5i+2DgCOD08syLgGttzwGuLdu7qg8Bd9S2Pw18wfaLgIeAUztSqolzAfB9238GvILqn8Wk\n+P1LmgGcCfTafhnVQKATmHx/A9stSaU1T00HY/sPwOB0MLss25ts31zWH6X6D8oMqudeXg5bDhzX\nmRK2l6SZwLHA18q2gDcC3y6H7LLPDiDpucDrgaUAtv9g+zdMkt9/sRuwp6TdgD8FNjGJ/gbGK0ml\nNcNNBzOjQ2WZcJJmAYcANwLTbG8qu+4HpnWoWO32ReBvgT+W7ecBv7G9tWzv6n8Ds4EB4OulCfBr\nkp7DJPn9294IfBb4N6pk8jCwhsn1NzAuSSoxKkl7AVcAZ9l+pL7P1dDBXW74oKS3AZttr+l0WTpo\nN+CVwEW2DwF+x5Cmrl319w9Q+ormUyXXFwDPAeZ1tFBdIkmlNS1NB7OrkfQsqoRyie0rS/gBSdPL\n/unA5k6Vr41eA7xd0gaqps43UvUv7FuaQmDX/xvoB/pt31i2v02VZCbD7x/gTcA9tgdsPwFcSfV3\nMZn+BsYlSaU1k246mNKHsBS4w/bna7tWAAvK+gLgqokuW7vZPtv2TNuzqH7XP7T9buA64J3lsF3y\n2QfZvh+4T9JLSugoqk9K7PK//+LfgCMk/Wn5d2Hw+SfN38B45eXHFkk6hqqdfXA6mPM7XKS2kvRa\n4F+BdTzdr/Axqn6Vy4EDgXuB421v6UghJ4CkI4GP2n6bpIOoai77AbcA/832450sXztJmks1UGF3\n4G7gFKr/EZ0Uv39JnwDeRTUS8hbgr6j6UCbN38B4JKlERERj0vwVERGNSVKJiIjGJKlERERjklQi\nIqIxSSoREdGYJJWY1CT9tg3XnFuGoA9unyvpoztwvb8oswRfNyQ+S9LvyzQqd0i6SdLJ21u+iCZ1\n/ZcfI3ZCc4Femvsi6anAabZ/Msy+u8o0KpT3aK6UJNtfn8DyRTwlNZWIQtLfSFot6dby4ttgbeAO\nSV8t39b4gaQ9y75XlWPXSvpM+e7G7sB5wLtK/F3l8gdL+pGkuyWdOcL9T5S0rlzn0yX2P4HXAksl\nfWa08tu+G/gw1ZTtSDpM0s9KTeankl4yXPmGO26H/2HG5GU7S5ZJuwC/LT+PpvoGuaj+Z+tqqqnf\nZ1G9UT23HHc51VvUALcBry7ri4HbyvrJwD/W7nEu8FNgD2B/4EHgWUPK8QKqqUF6qFoQfggcV/b9\niOq7HkPLPmvwnrXYvsDvy/o+wG5l/U3AFSOUb9jjsmQZz5Lmr4jK0WW5pWzvBcyh+g/9PbbXlvga\nYJakfYG9bf+sxL8JvG2U63/X1XQej0vaTDVlfH9t/6uAH9keAJB0CVVS++ftfA7V1p8LLJc0h2o2\n4WeNcE6rx0WMKc1fERUBf297blleZHtp2Vef2+lJxtcX2cQ1WnEIT3+t8pPAda6+XPjnwLNHOKfV\n4yLGlKQSUbkGeG/5fgySZkh6/kgHu/oK4qOSDi+hE2q7HwX23s773wT8Z0n7l89Xnwhcvz0XKB9T\n+yzwpRJ6Lk9PzX7yKOUb6biI7ZakEgHY/gFVE9bPJK2j+n7IWInhVOCrktZSfcTp4RK/jqpjvt5R\nP9b9N1F9BOs64OfAGtutTKv+wsEhxVT9PRf66ZFf/wD8vaRbeGbNaGj5RjouYrtlluKIcZK0l+3f\nlvVFwHTbH+pwsSI6Kv9XEjF+x0o6m+rfo3tJ01FEaioREdGc9KlERERjklQiIqIxSSoREdGYJJWI\niGhMkkpERDQmSSUiIhrz/wEE/kTLCb2OZgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93IRXBwgS5UT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 30\n",
        "x_train = sequence.pad_sequences(X_train, maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH06qeM489iA",
        "colab_type": "code",
        "outputId": "4bf0eb79-132b-45af-b4f6-1ce8549b26ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "IufJ9A4DS5UY",
        "colab_type": "code",
        "outputId": "c304066d-13d3-4880-8877-971208374074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 64)) #embedding size보다 1은 커야함\n",
        "model.add(LSTM(64))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print('Train...')\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0812 01:47:16.506520 140275144341376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0812 01:47:16.550173 140275144341376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0812 01:47:16.560006 140275144341376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0812 01:47:16.836024 140275144341376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0812 01:47:16.846986 140275144341376 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0812 01:47:16.877528 140275144341376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0812 01:47:16.901939 140275144341376 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0812 01:47:16.908966 140275144341376 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/10\n",
            "150000/150000 [==============================] - 49s 325us/step - loss: 0.4864 - acc: 0.7661\n",
            "Epoch 2/10\n",
            "150000/150000 [==============================] - 45s 298us/step - loss: 0.3329 - acc: 0.8575\n",
            "Epoch 3/10\n",
            "150000/150000 [==============================] - 46s 308us/step - loss: 0.3091 - acc: 0.8676\n",
            "Epoch 4/10\n",
            "150000/150000 [==============================] - 45s 302us/step - loss: 0.2949 - acc: 0.8726\n",
            "Epoch 5/10\n",
            "150000/150000 [==============================] - 46s 305us/step - loss: 0.2811 - acc: 0.8779\n",
            "Epoch 6/10\n",
            "150000/150000 [==============================] - 46s 304us/step - loss: 0.2679 - acc: 0.8832\n",
            "Epoch 7/10\n",
            "150000/150000 [==============================] - 45s 301us/step - loss: 0.2547 - acc: 0.8889\n",
            "Epoch 8/10\n",
            "150000/150000 [==============================] - 51s 339us/step - loss: 0.2450 - acc: 0.8931\n",
            "Epoch 9/10\n",
            "150000/150000 [==============================] - 45s 301us/step - loss: 0.2319 - acc: 0.8985\n",
            "Epoch 10/10\n",
            "150000/150000 [==============================] - 45s 302us/step - loss: 0.2204 - acc: 0.9040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9418686a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv17qpumS5Ua",
        "colab_type": "code",
        "outputId": "ec5ccd80-aa43-45d3-966b-7dcdf6833b37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          640000    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 673,154\n",
            "Trainable params: 673,154\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YKkVoqzzfOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('lstm.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWK32sUaS5Ud",
        "colab_type": "code",
        "outputId": "3b65a83e-22f0-4174-d8aa-cc54552d758a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 8s 167us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRedD4xWS5Uf",
        "colab_type": "code",
        "outputId": "817e132e-b900-4288-f1f1-8922a2d45ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "results"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4237879145002365, 0.83947]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rDX2FSpS5Ui",
        "colab_type": "text"
      },
      "source": [
        "### 3. LRP & Visualization (base code : https://github.com/ArrasL/LRP_for_LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-R6Q2AhS5Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def html_heatmap (words, scores, cmap_name=\"bwr\"):\n",
        "    \"\"\"\n",
        "    Return word-level heatmap in HTML format,\n",
        "    with words being the list of words (as string),\n",
        "    scores the corresponding list of word-level relevance values,\n",
        "    and cmap_name the name of the matplotlib diverging colormap.\n",
        "    \"\"\"\n",
        "    \n",
        "    colormap  = plt.get_cmap(cmap_name)\n",
        "     \n",
        "    #assert len(words)==len(scores)\n",
        "    max_s     = max(scores)\n",
        "    min_s     = min(scores)\n",
        "    \n",
        "    output_text = \"\"\n",
        "    \n",
        "    for idx, w in enumerate(words):\n",
        "        score       = rescale_score_by_abs(scores[idx], max_s, min_s)\n",
        "        output_text = output_text + span_word(w, score, colormap) + \" \"\n",
        "    \n",
        "    return output_text + \"\\n\"\n",
        "\n",
        "def rescale_score_by_abs (score, max_score, min_score):\n",
        "    \"\"\"\n",
        "    Normalize the relevance value (=score), accordingly to the extremal relevance values (max_score and min_score), \n",
        "    for visualization with a diverging colormap.\n",
        "    i.e. rescale positive relevance to the range [0.5, 1.0], and negative relevance to the range [0.0, 0.5],\n",
        "    using the highest absolute relevance for linear interpolation.\n",
        "    \"\"\"\n",
        "    \n",
        "    # CASE 1: positive AND negative scores occur --------------------\n",
        "    if max_score>0 and min_score<0:\n",
        "    \n",
        "        if max_score >= abs(min_score):   # deepest color is positive\n",
        "            if score>=0:\n",
        "                return 0.5 + 0.5*(score/max_score)\n",
        "            else:\n",
        "                return 0.5 - 0.5*(abs(score)/max_score)\n",
        "\n",
        "        else:                             # deepest color is negative\n",
        "            if score>=0:\n",
        "                return 0.5 + 0.5*(score/abs(min_score))\n",
        "            else:\n",
        "                return 0.5 - 0.5*(score/min_score)   \n",
        "    \n",
        "    # CASE 2: ONLY positive scores occur -----------------------------       \n",
        "    elif max_score>0 and min_score>=0: \n",
        "        if max_score == min_score:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return 0.5 + 0.5*(score/max_score)\n",
        "    \n",
        "    # CASE 3: ONLY negative scores occur -----------------------------\n",
        "    elif max_score<=0 and min_score<0: \n",
        "        if max_score == min_score:\n",
        "            return 0.0\n",
        "        else:\n",
        "            return 0.5 - 0.5*(score/min_score)\n",
        "          \n",
        "\n",
        "def getRGB (c_tuple):\n",
        "    return \"#%02x%02x%02x\"%(int(c_tuple[0]*255), int(c_tuple[1]*255), int(c_tuple[2]*255))\n",
        "\n",
        "     \n",
        "def span_word (word, score, colormap):\n",
        "    return \"<span style=\\\"background-color:\"+getRGB(colormap(score))+\"\\\">\"+word+\"</span>\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4no2JyfS5Uw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_layer_output(layer_name, data):\n",
        "    # https://keras.io/getting-started/faq/#how-can-i-obtain-the-output-of-an-intermediate-layer\n",
        "    intermediate_layer_model = keras.Model(inputs=model.input,\n",
        "                                     outputs=model.get_layer(layer_name).output)\n",
        "    return intermediate_layer_model.predict(data)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toKXGVMXS5Ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = [weight.name for layer in model.layers for weight in layer.weights]\n",
        "weights = model.get_weights()\n",
        "\n",
        "# suppress scientific notation\n",
        "np.set_printoptions(suppress=True)\n",
        "for name, weight in zip(names, weights):\n",
        "    if name == 'lstm_1/kernel:0':\n",
        "        kernel_0 = weight\n",
        "    if name == 'lstm_1/recurrent_kernel:0':\n",
        "        recurrent_kernel_0 = weight\n",
        "    if name == 'lstm_1/bias:0':\n",
        "        bias_0 = weight\n",
        "    elif name == 'dense_1/kernel:0':\n",
        "        output = weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKCNlYJuS5U2",
        "colab_type": "code",
        "outputId": "97a4a8a7-0ffe-48f8-dd3d-7c8a1d624afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(\"kernel_0\", kernel_0.shape)\n",
        "print(\"recurrent_kernel_0\", recurrent_kernel_0.shape)\n",
        "print(\"bias_0\", bias_0.shape)\n",
        "print(\"output\", output.shape)\n",
        "\n",
        "# self.Wxh_Left (240, 60)\n",
        "# self.Whh_Left (240, 60)\n",
        "# self.bxh_Left (240,)\n",
        "# self.Why_Left (5, 60)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kernel_0 (64, 256)\n",
            "recurrent_kernel_0 (64, 256)\n",
            "bias_0 (256,)\n",
            "output (64, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "638-oeUdqgkq",
        "colab_type": "code",
        "outputId": "67a66bd5-3398-4afe-962b-96da19236c3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "Wxh = kernel_0  # shape 4d*e\n",
        "Whh = recurrent_kernel_0  # shape 4d\n",
        "bxh = bias_0  # shape 4d \n",
        "Why = output\n",
        "\n",
        "print(\"Wxh\", Wxh.shape)\n",
        "print(\"Whh\", Whh.shape)\n",
        "print(\"bxh\", bxh.shape)\n",
        "print(\"Why\", Why.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wxh (64, 256)\n",
            "Whh (64, 256)\n",
            "bxh (256,)\n",
            "Why (64, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1KbcZ-dS5U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor=0.0, debug=False):\n",
        "    \"\"\"\n",
        "    LRP for a linear layer with input dim D and output dim M.\n",
        "    Args:\n",
        "    - hin:            forward pass input, of shape (D,)\n",
        "    - w:              connection weights, of shape (D, M)\n",
        "    - b:              biases, of shape (M,)\n",
        "    - hout:           forward pass output, of shape (M,) (unequal to np.dot(w.T,hin)+b if more than one incoming layer!)\n",
        "    - Rout:           relevance at layer output, of shape (M,)\n",
        "    - bias_nb_units:  total number of connected lower-layer units (onto which the bias/stabilizer contribution is redistributed for sanity check)\n",
        "    - eps:            stabilizer (small positive number)\n",
        "    - bias_factor:    set to 1.0 to check global relevance conservation, otherwise use 0.0 to ignore bias/stabilizer redistribution (recommended)\n",
        "    Returns:\n",
        "    - Rin:            relevance at layer input, of shape (D,)\n",
        "    \"\"\"\n",
        "    sign_out = np.where(hout[na,:]>=0, 1., -1.) # shape (1, M)\n",
        "    numer    = (hin[:,na] * w) + ( bias_factor * (b[na,:]*1. + eps*sign_out*1.) / bias_nb_units ) # shape (D, M)\n",
        "    denom    = hout[na,:] + (eps*sign_out*1.)   # shape (1, M)\n",
        "    message  = (numer/denom) * Rout[na,:]       # shape (D, M)\n",
        "    \n",
        "    Rin      = message.sum(axis=1)              # shape (D,)\n",
        "    \n",
        "    if debug:\n",
        "        print(\"local diff: \", Rout.sum() - Rin.sum())\n",
        "\n",
        "    return Rin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDAH9-Q4S5U7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LRP(target_data, target_class) :\n",
        "    \n",
        "    #원본 소스에서 E embedding은 전체에 대한 단어 사전이고, x는 embedding된 인풋이다.  \n",
        "    # w_indices [109, 11995, 25, 18263, 25, 973, 3138, 6389, 372]\n",
        "\n",
        "    x = get_layer_output('embedding_1', target_data).squeeze(axis=1)\n",
        "    e = x.shape[1]\n",
        "\n",
        "   ################# forword\n",
        "    T = target_data.shape[0]\n",
        "    d = int(256/4)  # hidden units\n",
        "    C = Why.shape[1] # number of classes\n",
        "    \n",
        "    idx    = np.hstack((np.arange(0,d), np.arange(2*d,4*d))).astype(int) # indices of gates i,f,o together\n",
        "    idx_i, idx_g, idx_f, idx_o = np.arange(0,d), np.arange(d,2*d), np.arange(2*d,3*d), np.arange(3*d,4*d) # indices of gates i,g,f,o separately\n",
        "\n",
        "    h  = np.zeros((T,d))\n",
        "    c  = np.zeros((T,d))\n",
        "\n",
        "    gates_xh  = np.zeros((T, 4*d))  \n",
        "    gates_hh  = np.zeros((T, 4*d)) \n",
        "    gates_pre = np.zeros((T, 4*d))  \n",
        "    gates     = np.zeros((T, 4*d))  \n",
        "\n",
        "    for t in range(T):\n",
        "        gates_xh[t]     = np.dot(Wxh.T, x[t])\n",
        "        gates_hh[t]     = np.dot(Whh.T, h[t-1])\n",
        "        gates_pre[t]    = gates_xh[t] + gates_hh[t] + bxh\n",
        "        gates[t, idx]    = 1.0/(1.0 + np.exp(- gates_pre[t,idx]))\n",
        "        gates[t,idx_g]  = np.tanh(gates_pre[t,idx_g]) \n",
        "        c[t]            = gates[t,idx_f]*c[t-1] + gates[t,idx_i]*gates[t,idx_g]\n",
        "        h[t]            = gates[t,idx_o]*np.tanh(c[t])\n",
        "\n",
        "    s = np.dot(Why.T, h[t])    \n",
        "\n",
        "    ################# backwork\n",
        "    dx     = np.zeros(x.shape)\n",
        "\n",
        "    dh          = np.zeros((T, d))\n",
        "    dc          = np.zeros((T, d))\n",
        "    dgates_pre  = np.zeros((T, 4*d))  # gates pre-activation\n",
        "    dgates      = np.zeros((T, 4*d))  # gates activation\n",
        "\n",
        "    ds               = np.zeros((C))\n",
        "    ds[target_class] = 1.0\n",
        "    dy               = ds.copy()\n",
        "\n",
        "    #맨처음을 0으로 시작하지 않게 위한조치\n",
        "    dh[T-1]     = np.dot(Why, dy)\n",
        "\n",
        "    for t in reversed(range(T)): \n",
        "        dgates[t,idx_o]    = dh[t] * np.tanh(c[t])  # do[t]\n",
        "        dc[t]             += dh[t] * gates[t,idx_o] * (1.-(np.tanh(c[t]))**2) # dc[t]\n",
        "        dgates[t,idx_f]    = dc[t] * c[t-1]         # df[t]\n",
        "        dc[t-1]            = dc[t] * gates[t,idx_f] # dc[t-1]\n",
        "        dgates[t,idx_i]    = dc[t] * gates[t,idx_g] # di[t]\n",
        "        dgates[t,idx_g]    = dc[t] * gates[t,idx_i] # dg[t]\n",
        "        dgates_pre[t,idx]  = dgates[t,idx] * gates[t,idx] * (1.0 - gates[t,idx]) # d ifo pre[t]\n",
        "        dgates_pre[t,idx_g]= dgates[t,idx_g] *  (1.-(gates[t,idx_g])**2) # d g pre[t]\n",
        "        dh[t-1]            = np.dot(Whh, dgates_pre[t])\n",
        "        dx[t]              = np.dot(Wxh, dgates_pre[t])\n",
        "\n",
        "    ################# LRP\n",
        "    eps=0.001 \n",
        "    bias_factor=0.0\n",
        "    Rx  = np.zeros(x.shape)\n",
        "    Rh  = np.zeros((T+1, d))\n",
        "    Rc  = np.zeros((T+1, d))\n",
        "    Rg  = np.zeros((T,   d)) # gate g only\n",
        "\n",
        "    Rout_mask            = np.zeros((C))\n",
        "    Rout_mask[target_class] = 1.0  \n",
        "\n",
        "    # format reminder: lrp_linear(hin, w, b, hout, Rout, bias_nb_units, eps, bias_factor)\n",
        "    Rh[T-1]  = lrp_linear(h[T-1], Why, np.zeros((C)), s, s*Rout_mask, 2*d, eps, bias_factor, debug=False)  \n",
        "\n",
        "    for t in reversed(range(T)):\n",
        "        print(\"gates[t,idx_f]*c[t-1],\",gates[t,idx_f]*c[t-1].shape)\n",
        "        print(\"gates[t,idx_i]*gates[t,idx_g]\",gates[t,idx_i]*gates[t,idx_g].shape)\n",
        "        print(\"h[T-1]\",h[T-1].shape)\n",
        "        print(\"x[t]\",x[t].shape)\n",
        "        Rc[t]   += Rh[t]\n",
        "        Rc[t-1]  = lrp_linear(gates[t,idx_f]*c[t-1], np.identity(d), np.zeros((d)), c[t], Rc[t], 2*d, eps, bias_factor, debug=False)\n",
        "        Rg[t]    = lrp_linear(gates[t,idx_i]*gates[t,idx_g], np.identity(d), np.zeros((d)), c[t], Rc[t], 2*d, eps, bias_factor, debug=False)\n",
        "        Rx[t]    = lrp_linear(x[t], Wxh[idx_g], bxh[idx_g], gates_pre[t,idx_g], Rg[t], d+e, eps, bias_factor, debug=False)\n",
        "        Rh[t-1]  = lrp_linear(h[t-1], Whh[idx_g], bxh[idx_g], gates_pre[t,idx_g], Rg[t], d+e, eps, bias_factor, debug=False)    \n",
        "\n",
        "    return s, dx, Rx, Rh[-1].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9SR9LoOS5VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index_to_word(list):\n",
        "    _ = []\n",
        "    for x in list :\n",
        "        _.append(selected_words_10000[x].split('/')[0])\n",
        "    return _"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdOy0NVuS5VZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def int_to_str(target_class):\n",
        "    if target_class == 0 :\n",
        "        return \"부정\"\n",
        "    else :\n",
        "        return \"긍정\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "470zKQDJS5Vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2HWZRNXS5Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_list = []\n",
        "negative_list = []\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if np.argmax(predictions[i]) == 1:\n",
        "        positive_list.append(i)\n",
        "    else :\n",
        "        negative_list.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FUPZ-t-Eyub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#selected_words_10000.append(selected_words_10000[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "vjQD2HlRS5Vh",
        "colab_type": "code",
        "outputId": "c249d083-a036-47f4-cd35-33378d543a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        }
      },
      "source": [
        "print(\"각 단어가 긍정이라고 예측하는데 영향을 미치는 정도\" )\n",
        "for index, i in enumerate(positive_list):\n",
        "    \n",
        "    target_full_data = x_test[i]\n",
        "    squeeze_index = np.transpose(np.nonzero(target_full_data)).squeeze(axis=1)\n",
        "\n",
        "    target_data = np.array(target_full_data[squeeze_index])\n",
        "    target_class = np.argmax(y_test[i])\n",
        "\n",
        "    scores, Gx, Rx, R_rest = LRP(target_data, target_class)\n",
        "\n",
        "    R_words          = np.sum(Rx, axis=1)                       # compute word-level LRP relevances\n",
        "    \n",
        "    \n",
        "    R_words_SA       = (np.linalg.norm(Gx,ord=2, axis=0))**2   # compute word-level Sensitivity Analysis relevances\n",
        "    R_words_GI       = np.dot(target_data, Gx) \n",
        "\n",
        "    words = index_to_word(target_data)\n",
        "\n",
        "    if len(words) > 0 :\n",
        "        print(\" 예측 레이블:\", int_to_str(np.argmax(predictions[i])), \"| 실제 레이블 : \", int_to_str(target_class))\n",
        "\n",
        "        print(\"        LRP heatmap:\")\n",
        "        display(HTML(html_heatmap(words, R_words)))\n",
        "\n",
        "        print(\"        SA heatmap:\")\n",
        "        display(HTML(html_heatmap(words, R_words_SA)))\n",
        "\n",
        "        print(\"        GI heatmap:\")\n",
        "        display(HTML(html_heatmap(words, R_words_GI)))\n",
        "\n",
        "        print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    if index == 20: # 50개만 출력\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "각 단어가 긍정이라고 예측하는데 영향을 미치는 정도\n",
            "gates[t,idx_f]*c[t-1], [32.43477416 34.11802459 31.95602827 32.59127186 31.56421784 34.08392178\n",
            " 29.1779946  25.92206883 32.71766237 33.05716962 27.64401921 35.00184965\n",
            " 32.12492425 31.73841638 26.23886833 30.46675771 29.86564097 31.10416144\n",
            " 31.77091261 32.70106766 31.12399924 34.88045275 27.05372544 38.96504109\n",
            " 26.79443585 33.31779794 30.36203396 34.30087779 33.02871724 28.69263961\n",
            " 30.9801979  35.98913839 35.22221895 31.18008402 34.08530954 31.55567501\n",
            " 27.86726366 32.01609506 31.35758653 28.92248125 36.85230347 32.19655969\n",
            " 32.9190286  27.73241259 28.69127411 30.31522855 26.17192305 29.86087693\n",
            " 27.08406542 34.85774126 31.34296374 31.29120937 35.79117904 31.36155123\n",
            " 31.80985493 32.71405412 30.18843317 30.43606527 34.21991497 36.42778389\n",
            " 30.18859722 35.55377792 31.3430472  30.89230854]\n",
            "gates[t,idx_i]*gates[t,idx_g] [37.32598458 38.3538905  35.40537847 33.73940399 38.33659347 36.8959718\n",
            " 37.81609017 30.28197748 35.89136337 32.87782001 36.40663276 41.3487084\n",
            " 32.6301326  40.9246202  38.35470258 29.76100151 33.04182808 39.12926825\n",
            " 32.74135604 36.47767462 32.97706381 32.36278717 34.49225853 33.87803032\n",
            " 36.84343017 33.62242244 36.95242055 33.49376148 37.56191519 40.11484065\n",
            " 32.79121311 31.348766   32.5638967  41.015822   32.65225749 34.10508601\n",
            " 34.81243237 38.02332426 40.54763791 33.59386668 33.58797988 33.67260719\n",
            " 31.3338737  35.80482022 29.24905883 24.99473758 39.90377507 40.38135279\n",
            " 37.713262   32.24195584 30.54367267 32.5856239  37.28565774 36.19844313\n",
            " 34.64838355 35.90096613 37.66846834 34.86209595 33.22196231 29.67019774\n",
            " 36.03243398 35.80126339 34.5526409  37.03652944]\n",
            "h[T-1] (64,)\n",
            "x[t] (64,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-823523ef5d05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtarget_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_rest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLRP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mR_words\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m                       \u001b[0;31m# compute word-level LRP relevances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-7e084979af19>\u001b[0m in \u001b[0;36mLRP\u001b[0;34m(target_data, target_class)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mRc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlrp_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_f\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mRg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlrp_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_i\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mRx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mlrp_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWxh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgates_pre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mRh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mlrp_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWhh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbxh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgates_pre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx_g\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for axis 0 with size 64"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "M_AO1yd0S5Vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"각 단어가 부정정이라고 예측하는데 영향을 미치는 정도\" )\n",
        "for index, i in enumerate(negative_list):\n",
        "    \n",
        "    target_full_data = x_test[i]\n",
        "    squeeze_index = np.transpose(np.nonzero(target_full_data)).squeeze(axis=1)\n",
        "    print(squeeze_index)\n",
        "\n",
        "    target_data = np.array(target_full_data[squeeze_index])\n",
        "    print(\"target_data\",target_data.shape)\n",
        "    target_class = np.argmax(y_test[i])\n",
        "\n",
        "    scores, Gx, Rx, R_rest = LRP(target_data, target_class)\n",
        "\n",
        "    R_words             = np.sum(Rx, axis=1)                    # compute word-level LRP relevances\n",
        "    \n",
        "    R_words_SA       = (np.linalg.norm(Gx, ord=2, axis=0))**2   # compute word-level Sensitivity Analysis relevances\n",
        "    \n",
        "    R_words_GI       = np.dot(target_data, Gx) \n",
        "\n",
        "    words = index_to_word(target_data)\n",
        "\n",
        "    if len(words) > 0 :\n",
        "        print(\" 예측 레이블:\", int_to_str(np.argmax(predictions[i])), \"| 실제 레이블 : \", int_to_str(target_class))\n",
        "\n",
        "        print(\"        LRP heatmap:\")\n",
        "        display(HTML(html_heatmap(words, R_words)))\n",
        "\n",
        "        print(\"        SA heatmap:\")\n",
        "        display(HTML(html_heatmap(words, R_words_SA)))\n",
        "\n",
        "        print(\"        GI heatmap:\")\n",
        "        display(HTML(html_heatmap(words, R_words_GI)))\n",
        "\n",
        "        print(\"-----------------------------------------------------------\")\n",
        "\n",
        "    if index == 20: # 50개만 출력\n",
        "      break"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}